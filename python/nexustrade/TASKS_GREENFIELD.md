# NexusTrade - Greenfield Implementation Tasks

This document describes greenfield implementation tasks that require building **new modules from scratch** while integrating with the existing NexusTrade trading platform architecture.

Each task provides:
- A complete Python interface contract (class with method signatures and docstrings)
- Required data models and structures
- Architectural patterns to follow (from existing codebase)
- Acceptance criteria including tests, coverage, and integration points

---

## Task 1: Market Surveillance Engine

### Overview

Implement a **Market Surveillance Engine** that detects market manipulation patterns in real-time. This service monitors trading activity across all symbols and users, identifying suspicious patterns such as spoofing, layering, wash trading, and momentum ignition.

### Business Context

Regulatory compliance (SEC Rule 15c3-5, MiFID II) requires trading platforms to monitor for market manipulation. The surveillance engine must process trade and order events in real-time, flag suspicious activity, and generate alerts for compliance review.

### Service Location

```
services/surveillance/
    __init__.py
    settings.py
    models.py
    engine.py
    detectors/
        __init__.py
        spoofing.py
        wash_trading.py
        layering.py
        momentum.py
    views.py
    urls.py
    asgi.py
```

### Interface Contract

```python
"""
Market Surveillance Engine - Interface Contract

Location: services/surveillance/engine.py
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime, timedelta
from decimal import Decimal
from enum import Enum
from typing import Optional, List, Dict, Any
from uuid import UUID


class ManipulationType(Enum):
    """Types of market manipulation patterns."""
    SPOOFING = "spoofing"              # Large orders placed and cancelled quickly
    LAYERING = "layering"              # Multiple orders at different price levels
    WASH_TRADING = "wash_trading"      # Self-trading to create artificial volume
    MOMENTUM_IGNITION = "momentum"     # Orders designed to trigger other orders
    FRONT_RUNNING = "front_running"    # Trading ahead of known large orders
    QUOTE_STUFFING = "quote_stuffing"  # High-frequency order submission/cancellation


class AlertSeverity(Enum):
    """Alert severity levels."""
    LOW = "low"           # Pattern detected, below threshold
    MEDIUM = "medium"     # Pattern confirmed, requires review
    HIGH = "high"         # Strong indication, immediate review
    CRITICAL = "critical" # Clear violation, halt trading


@dataclass
class SurveillanceAlert:
    """Alert generated by the surveillance engine."""
    alert_id: UUID
    alert_type: ManipulationType
    severity: AlertSeverity
    user_id: UUID
    symbol: str
    detected_at: datetime
    description: str
    evidence: Dict[str, Any]  # Supporting data for the alert
    related_order_ids: List[UUID]
    confidence_score: float  # 0.0 to 1.0
    recommended_action: str


@dataclass
class TradingPattern:
    """Detected trading pattern for analysis."""
    user_id: UUID
    symbol: str
    pattern_type: str
    start_time: datetime
    end_time: datetime
    order_count: int
    total_volume: Decimal
    cancel_rate: float
    metrics: Dict[str, float]


class PatternDetector(ABC):
    """Abstract base class for manipulation pattern detectors."""

    @abstractmethod
    def detect(
        self,
        orders: List[Dict[str, Any]],
        trades: List[Dict[str, Any]],
        window: timedelta,
    ) -> List[SurveillanceAlert]:
        """
        Detect manipulation patterns in the given data window.

        Args:
            orders: List of order events (created, modified, cancelled)
            trades: List of executed trades
            window: Time window for analysis

        Returns:
            List of alerts for detected patterns
        """
        pass

    @abstractmethod
    def get_threshold_config(self) -> Dict[str, float]:
        """
        Get the configurable thresholds for this detector.

        Returns:
            Dictionary of threshold names to default values
        """
        pass


class SurveillanceEngine:
    """
    Real-time market surveillance engine.

    Monitors trading activity and detects market manipulation patterns.
    Integrates with Kafka for event consumption and generates alerts
    for the compliance team.
    """

    def __init__(
        self,
        kafka_bootstrap_servers: str,
        redis_url: str,
        alert_callback: Optional[callable] = None,
    ):
        """
        Initialize the surveillance engine.

        Args:
            kafka_bootstrap_servers: Kafka connection string
            redis_url: Redis URL for caching and state
            alert_callback: Optional callback for alert notifications
        """
        pass

    async def start(self) -> None:
        """
        Start the surveillance engine.

        Begins consuming events from Kafka and running detection algorithms.
        """
        pass

    async def stop(self) -> None:
        """
        Stop the surveillance engine gracefully.

        Flushes pending alerts and closes connections.
        """
        pass

    def register_detector(
        self,
        detector: PatternDetector,
        symbols: Optional[List[str]] = None,
    ) -> None:
        """
        Register a pattern detector with the engine.

        Args:
            detector: The detector instance to register
            symbols: Optional list of symbols to monitor (None = all)
        """
        pass

    async def process_order_event(
        self,
        event: Dict[str, Any],
    ) -> List[SurveillanceAlert]:
        """
        Process an incoming order event.

        Args:
            event: Order event (created, modified, cancelled)

        Returns:
            List of alerts triggered by this event
        """
        pass

    async def process_trade_event(
        self,
        event: Dict[str, Any],
    ) -> List[SurveillanceAlert]:
        """
        Process an incoming trade event.

        Args:
            event: Trade execution event

        Returns:
            List of alerts triggered by this event
        """
        pass

    async def get_user_profile(
        self,
        user_id: UUID,
        lookback_days: int = 30,
    ) -> Dict[str, Any]:
        """
        Get trading profile for a user.

        Args:
            user_id: User to analyze
            lookback_days: Days of history to consider

        Returns:
            Profile including typical patterns, volumes, symbols traded
        """
        pass

    async def get_symbol_profile(
        self,
        symbol: str,
        lookback_days: int = 30,
    ) -> Dict[str, Any]:
        """
        Get trading profile for a symbol.

        Args:
            symbol: Symbol to analyze
            lookback_days: Days of history to consider

        Returns:
            Profile including typical volume, spread, volatility
        """
        pass

    async def run_historical_scan(
        self,
        start_time: datetime,
        end_time: datetime,
        symbols: Optional[List[str]] = None,
        users: Optional[List[UUID]] = None,
    ) -> List[SurveillanceAlert]:
        """
        Run surveillance on historical data.

        Args:
            start_time: Start of analysis period
            end_time: End of analysis period
            symbols: Optional filter by symbols
            users: Optional filter by users

        Returns:
            All alerts detected in the period
        """
        pass

    def update_thresholds(
        self,
        detector_type: ManipulationType,
        thresholds: Dict[str, float],
    ) -> None:
        """
        Update detection thresholds dynamically.

        Args:
            detector_type: Type of detector to update
            thresholds: New threshold values
        """
        pass
```

### Required Models

```python
"""
Surveillance service Django models.

Location: services/surveillance/models.py
"""
from decimal import Decimal
from uuid import uuid4
from django.db import models


class SurveillanceAlert(models.Model):
    """Persisted surveillance alert."""

    SEVERITY_CHOICES = [
        ("low", "Low"),
        ("medium", "Medium"),
        ("high", "High"),
        ("critical", "Critical"),
    ]

    STATUS_CHOICES = [
        ("open", "Open"),
        ("reviewing", "Under Review"),
        ("escalated", "Escalated"),
        ("dismissed", "Dismissed"),
        ("confirmed", "Confirmed Violation"),
    ]

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    alert_type = models.CharField(max_length=50, db_index=True)
    severity = models.CharField(max_length=20, choices=SEVERITY_CHOICES)
    status = models.CharField(max_length=20, choices=STATUS_CHOICES, default="open")
    user_id = models.UUIDField(db_index=True)
    symbol = models.CharField(max_length=20, db_index=True)
    description = models.TextField()
    evidence = models.JSONField()
    related_order_ids = models.JSONField(default=list)
    confidence_score = models.DecimalField(max_digits=5, decimal_places=4)
    recommended_action = models.TextField()
    detected_at = models.DateTimeField(db_index=True)
    reviewed_at = models.DateTimeField(null=True, blank=True)
    reviewed_by = models.UUIDField(null=True, blank=True)
    review_notes = models.TextField(blank=True)
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        app_label = "surveillance"
        db_table = "surveillance_alerts"
        indexes = [
            models.Index(fields=["user_id", "detected_at"]),
            models.Index(fields=["symbol", "detected_at"]),
            models.Index(fields=["status", "severity"]),
        ]


class TradingProfile(models.Model):
    """Cached trading profile for users and symbols."""

    PROFILE_TYPE_CHOICES = [
        ("user", "User Profile"),
        ("symbol", "Symbol Profile"),
    ]

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    profile_type = models.CharField(max_length=20, choices=PROFILE_TYPE_CHOICES)
    entity_id = models.CharField(max_length=50, db_index=True)  # user_id or symbol
    metrics = models.JSONField()  # avg_order_size, cancel_rate, typical_volume, etc.
    computed_at = models.DateTimeField(auto_now=True)
    lookback_days = models.IntegerField(default=30)

    class Meta:
        app_label = "surveillance"
        db_table = "trading_profiles"
        unique_together = [["profile_type", "entity_id"]]


class DetectorConfig(models.Model):
    """Configuration for pattern detectors."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    detector_type = models.CharField(max_length=50, unique=True)
    enabled = models.BooleanField(default=True)
    thresholds = models.JSONField()
    updated_at = models.DateTimeField(auto_now=True)
    updated_by = models.UUIDField(null=True, blank=True)

    class Meta:
        app_label = "surveillance"
        db_table = "detector_configs"
```

### Architectural Patterns to Follow

1. **Event Consumption**: Follow the pattern in `services/matching/main.py` for Kafka consumer setup
2. **Service Client**: Use `shared/clients/base.py` pattern for inter-service communication
3. **Event Publishing**: Use `shared/events/base.py` for alert event schema
4. **Caching**: Follow the Redis caching pattern in `services/risk/views.py` (but fix the staleness bugs!)
5. **Django Models**: Follow the model patterns in `services/orders/models.py`
6. **API Views**: Follow REST API patterns in `services/risk/views.py`

### Acceptance Criteria

#### Unit Tests (30+ tests)
- [ ] Test each detector type independently
- [ ] Test threshold configuration and updates
- [ ] Test confidence score calculation
- [ ] Test alert generation with various input patterns
- [ ] Test edge cases (empty data, single order, exact thresholds)

#### Integration Tests (15+ tests)
- [ ] Test Kafka event consumption pipeline
- [ ] Test Redis profile caching and invalidation
- [ ] Test database alert persistence
- [ ] Test alert deduplication across time windows
- [ ] Test coordination with Risk service for trading halts

#### Performance Tests (5+ tests)
- [ ] Process 10,000 events/second without backlog
- [ ] Historical scan of 1M orders completes in < 60 seconds
- [ ] Alert generation latency < 100ms from event receipt
- [ ] Memory usage stable under sustained load

#### Coverage Requirements
- [ ] Minimum 85% line coverage
- [ ] Minimum 80% branch coverage
- [ ] 100% coverage of detection algorithms

#### Integration Points
- [ ] Subscribe to `orders.*` Kafka topics (OrderCreatedEvent, OrderCancelledEvent)
- [ ] Subscribe to `trades.*` Kafka topics (TradeExecutedEvent)
- [ ] Publish to `surveillance.alerts` topic
- [ ] Call Risk service to halt trading on CRITICAL alerts
- [ ] Call Notifications service for alert delivery
- [ ] Expose REST API for compliance dashboard

---

## Task 2: Portfolio Analytics Service

### Overview

Implement a **Portfolio Analytics Service** that provides real-time and historical risk metrics for user portfolios. This service calculates VaR (Value at Risk), Expected Shortfall, Sharpe Ratio, Beta, correlation matrices, and other portfolio analytics.

### Business Context

Users and the platform need comprehensive portfolio analytics for risk management and investment decisions. The service must handle both real-time updates as positions change and batch calculations for end-of-day reporting.

### Service Location

```
services/analytics/
    __init__.py
    settings.py
    models.py
    calculators/
        __init__.py
        var.py
        performance.py
        risk_metrics.py
        correlation.py
    portfolio.py
    views.py
    urls.py
    asgi.py
```

### Interface Contract

```python
"""
Portfolio Analytics Service - Interface Contract

Location: services/analytics/portfolio.py
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass
from datetime import datetime, date
from decimal import Decimal
from enum import Enum
from typing import Optional, List, Dict, Tuple
from uuid import UUID


class VaRMethod(Enum):
    """Value at Risk calculation methods."""
    HISTORICAL = "historical"           # Historical simulation
    PARAMETRIC = "parametric"           # Variance-covariance (normal distribution)
    MONTE_CARLO = "monte_carlo"         # Monte Carlo simulation
    CORNISH_FISHER = "cornish_fisher"   # Adjusted for skewness/kurtosis


class TimeHorizon(Enum):
    """Time horizons for analytics calculations."""
    DAILY = "1D"
    WEEKLY = "1W"
    MONTHLY = "1M"
    QUARTERLY = "3M"
    YEARLY = "1Y"


@dataclass
class PortfolioPosition:
    """Single position in a portfolio."""
    symbol: str
    quantity: Decimal
    current_price: Decimal
    avg_cost: Decimal
    market_value: Decimal
    weight: Decimal  # Fraction of portfolio
    unrealized_pnl: Decimal
    realized_pnl: Decimal


@dataclass
class VaRResult:
    """Value at Risk calculation result."""
    var_amount: Decimal        # Dollar amount at risk
    var_percent: Decimal       # Percentage of portfolio
    confidence_level: float    # e.g., 0.95 or 0.99
    time_horizon: TimeHorizon
    method: VaRMethod
    calculated_at: datetime
    components: Dict[str, Decimal]  # Per-symbol contribution


@dataclass
class PerformanceMetrics:
    """Portfolio performance metrics."""
    total_return: Decimal         # Total return over period
    annualized_return: Decimal    # Annualized return
    sharpe_ratio: Decimal         # Risk-adjusted return
    sortino_ratio: Decimal        # Downside risk-adjusted return
    max_drawdown: Decimal         # Maximum peak-to-trough decline
    volatility: Decimal           # Standard deviation of returns
    beta: Decimal                 # Market sensitivity
    alpha: Decimal                # Excess return vs benchmark
    information_ratio: Decimal    # Active return per unit of tracking error
    treynor_ratio: Decimal        # Return per unit of market risk
    calmar_ratio: Decimal         # Return / max drawdown


@dataclass
class RiskDecomposition:
    """Portfolio risk decomposition."""
    total_risk: Decimal
    systematic_risk: Decimal      # Market risk (beta)
    idiosyncratic_risk: Decimal   # Stock-specific risk
    sector_contributions: Dict[str, Decimal]
    factor_exposures: Dict[str, Decimal]  # Size, value, momentum, etc.
    concentration_risk: Decimal   # HHI or similar measure


@dataclass
class CorrelationMatrix:
    """Correlation matrix for portfolio assets."""
    symbols: List[str]
    matrix: List[List[float]]     # NxN correlation matrix
    computed_at: datetime
    lookback_days: int

    def get_correlation(self, symbol1: str, symbol2: str) -> float:
        """Get correlation between two symbols."""
        pass


class PortfolioAnalyticsService:
    """
    Portfolio analytics and risk metrics service.

    Provides real-time and historical portfolio analytics including
    VaR, performance metrics, risk decomposition, and correlations.
    """

    def __init__(
        self,
        market_data_url: str,
        orders_service_url: str,
        redis_url: str,
        risk_free_rate: Decimal = Decimal("0.05"),
    ):
        """
        Initialize the analytics service.

        Args:
            market_data_url: URL for market data service
            orders_service_url: URL for orders/positions service
            redis_url: Redis URL for caching
            risk_free_rate: Annual risk-free rate for Sharpe calculation
        """
        pass

    async def get_portfolio_summary(
        self,
        user_id: UUID,
    ) -> Dict[str, Any]:
        """
        Get complete portfolio summary for a user.

        Args:
            user_id: User ID

        Returns:
            Summary including positions, market value, P&L, basic metrics
        """
        pass

    async def get_positions(
        self,
        user_id: UUID,
    ) -> List[PortfolioPosition]:
        """
        Get all positions for a user's portfolio.

        Args:
            user_id: User ID

        Returns:
            List of portfolio positions with current values
        """
        pass

    async def calculate_var(
        self,
        user_id: UUID,
        confidence_level: float = 0.99,
        time_horizon: TimeHorizon = TimeHorizon.DAILY,
        method: VaRMethod = VaRMethod.HISTORICAL,
        lookback_days: int = 252,
    ) -> VaRResult:
        """
        Calculate Value at Risk for a portfolio.

        Args:
            user_id: User ID
            confidence_level: Confidence level (0.95 or 0.99 typical)
            time_horizon: Time horizon for VaR
            method: Calculation method
            lookback_days: Historical data lookback period

        Returns:
            VaR result with amount, percentage, and breakdown
        """
        pass

    async def calculate_expected_shortfall(
        self,
        user_id: UUID,
        confidence_level: float = 0.99,
        time_horizon: TimeHorizon = TimeHorizon.DAILY,
    ) -> Decimal:
        """
        Calculate Expected Shortfall (CVaR) for a portfolio.

        Expected Shortfall is the expected loss given that VaR is exceeded.

        Args:
            user_id: User ID
            confidence_level: Confidence level
            time_horizon: Time horizon

        Returns:
            Expected shortfall amount
        """
        pass

    async def get_performance_metrics(
        self,
        user_id: UUID,
        start_date: date,
        end_date: date,
        benchmark_symbol: str = "SPY",
    ) -> PerformanceMetrics:
        """
        Calculate performance metrics for a period.

        Args:
            user_id: User ID
            start_date: Start of analysis period
            end_date: End of analysis period
            benchmark_symbol: Benchmark for relative metrics

        Returns:
            Complete performance metrics
        """
        pass

    async def get_risk_decomposition(
        self,
        user_id: UUID,
        factors: Optional[List[str]] = None,
    ) -> RiskDecomposition:
        """
        Decompose portfolio risk into components.

        Args:
            user_id: User ID
            factors: Optional list of risk factors to analyze

        Returns:
            Risk decomposition with systematic/idiosyncratic breakdown
        """
        pass

    async def get_correlation_matrix(
        self,
        user_id: Optional[UUID] = None,
        symbols: Optional[List[str]] = None,
        lookback_days: int = 252,
    ) -> CorrelationMatrix:
        """
        Calculate correlation matrix for portfolio or specified symbols.

        Args:
            user_id: Optional user ID (uses their positions)
            symbols: Optional explicit list of symbols
            lookback_days: Historical data lookback period

        Returns:
            Correlation matrix
        """
        pass

    async def calculate_marginal_var(
        self,
        user_id: UUID,
        symbol: str,
        quantity_change: Decimal,
    ) -> Decimal:
        """
        Calculate marginal VaR for adding/removing a position.

        Args:
            user_id: User ID
            symbol: Symbol to add/remove
            quantity_change: Quantity change (positive = add, negative = remove)

        Returns:
            Change in portfolio VaR
        """
        pass

    async def run_stress_test(
        self,
        user_id: UUID,
        scenarios: List[Dict[str, float]],
    ) -> List[Dict[str, Any]]:
        """
        Run stress test scenarios on portfolio.

        Args:
            user_id: User ID
            scenarios: List of scenarios, each mapping symbols to price changes

        Returns:
            List of scenario results with P&L impact
        """
        pass

    async def get_historical_returns(
        self,
        user_id: UUID,
        start_date: date,
        end_date: date,
        frequency: TimeHorizon = TimeHorizon.DAILY,
    ) -> List[Tuple[date, Decimal]]:
        """
        Get historical portfolio returns.

        Args:
            user_id: User ID
            start_date: Start date
            end_date: End date
            frequency: Return frequency

        Returns:
            List of (date, return) tuples
        """
        pass

    def invalidate_cache(
        self,
        user_id: UUID,
    ) -> None:
        """
        Invalidate cached analytics for a user.

        Call when positions change significantly.

        Args:
            user_id: User ID
        """
        pass
```

### Required Models

```python
"""
Analytics service Django models.

Location: services/analytics/models.py
"""
from decimal import Decimal
from uuid import uuid4
from django.db import models


class PortfolioSnapshot(models.Model):
    """Point-in-time portfolio snapshot for historical analysis."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    user_id = models.UUIDField(db_index=True)
    snapshot_date = models.DateField(db_index=True)
    total_value = models.DecimalField(max_digits=20, decimal_places=2)
    cash_balance = models.DecimalField(max_digits=20, decimal_places=2)
    positions_value = models.DecimalField(max_digits=20, decimal_places=2)
    daily_return = models.DecimalField(max_digits=10, decimal_places=6, null=True)
    positions = models.JSONField()  # Serialized position details
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        app_label = "analytics"
        db_table = "portfolio_snapshots"
        unique_together = [["user_id", "snapshot_date"]]
        indexes = [
            models.Index(fields=["user_id", "snapshot_date"]),
        ]


class RiskMetricCache(models.Model):
    """Cached risk metrics for quick retrieval."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    user_id = models.UUIDField(db_index=True)
    metric_type = models.CharField(max_length=50)  # var_99, sharpe, etc.
    metric_value = models.DecimalField(max_digits=20, decimal_places=8)
    parameters = models.JSONField()  # Calculation parameters
    computed_at = models.DateTimeField(auto_now=True)
    valid_until = models.DateTimeField()  # Cache expiry

    class Meta:
        app_label = "analytics"
        db_table = "risk_metric_cache"
        indexes = [
            models.Index(fields=["user_id", "metric_type"]),
        ]


class MarketDataCache(models.Model):
    """Cached market data for analytics calculations."""

    symbol = models.CharField(max_length=20, primary_key=True)
    current_price = models.DecimalField(max_digits=20, decimal_places=8)
    daily_return = models.DecimalField(max_digits=10, decimal_places=6)
    volatility_20d = models.DecimalField(max_digits=10, decimal_places=6)
    volatility_252d = models.DecimalField(max_digits=10, decimal_places=6)
    beta = models.DecimalField(max_digits=10, decimal_places=4)
    sector = models.CharField(max_length=50, blank=True)
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        app_label = "analytics"
        db_table = "market_data_cache"


class CorrelationCache(models.Model):
    """Cached correlation data between symbols."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    symbol1 = models.CharField(max_length=20, db_index=True)
    symbol2 = models.CharField(max_length=20, db_index=True)
    correlation = models.DecimalField(max_digits=8, decimal_places=6)
    lookback_days = models.IntegerField()
    computed_at = models.DateTimeField(auto_now=True)

    class Meta:
        app_label = "analytics"
        db_table = "correlation_cache"
        unique_together = [["symbol1", "symbol2", "lookback_days"]]
```

### Architectural Patterns to Follow

1. **Service Client Pattern**: Use `shared/clients/base.py` for calls to market-data and orders services
2. **Caching Strategy**: Use Redis with proper TTL and invalidation (avoid bugs in `services/risk/views.py`)
3. **Decimal Precision**: Use `Decimal` throughout for financial calculations (unlike the float bugs in existing code)
4. **Async Operations**: Follow async patterns for external service calls
5. **Event Consumption**: Subscribe to trade events for real-time position updates
6. **API Design**: Follow REST patterns from existing services

### Acceptance Criteria

#### Unit Tests (40+ tests)
- [ ] Test VaR calculations for each method (historical, parametric, Monte Carlo)
- [ ] Test Sharpe/Sortino ratio edge cases (zero volatility, negative returns)
- [ ] Test correlation matrix calculation with various portfolio sizes
- [ ] Test risk decomposition with single-stock and diversified portfolios
- [ ] Test decimal precision for all calculations (no float accumulation errors)

#### Integration Tests (20+ tests)
- [ ] Test market data service integration
- [ ] Test position data synchronization from orders service
- [ ] Test cache invalidation on position changes
- [ ] Test historical snapshot creation and retrieval
- [ ] Test stress test scenario execution

#### Performance Tests (5+ tests)
- [ ] VaR calculation for 100-position portfolio < 500ms
- [ ] Correlation matrix for 50 symbols < 1 second
- [ ] Monte Carlo VaR with 10,000 simulations < 2 seconds
- [ ] Historical returns retrieval for 5 years < 200ms

#### Coverage Requirements
- [ ] Minimum 90% line coverage
- [ ] Minimum 85% branch coverage
- [ ] 100% coverage of calculation algorithms

#### Integration Points
- [ ] Subscribe to `trades.*` Kafka topics for position updates
- [ ] Call Market Data service for price/return data
- [ ] Call Orders service for position data
- [ ] Expose REST API for frontend dashboard
- [ ] Expose WebSocket for real-time metric updates

---

## Task 3: Smart Order Router (SOR)

### Overview

Implement a **Smart Order Router** that optimizes order execution across multiple venues (internal matching engine, external exchanges). The SOR analyzes liquidity, fees, and execution probability to route orders for best execution.

### Business Context

Best execution requirements (SEC Rule 606, MiFID II) mandate that brokers route orders to venues offering the best combination of price, speed, and execution probability. The SOR must make routing decisions in microseconds while considering market conditions.

### Service Location

```
services/routing/
    __init__.py
    settings.py
    models.py
    router.py
    venues/
        __init__.py
        internal.py
        external.py
        venue_base.py
    strategies/
        __init__.py
        price_improvement.py
        speed_priority.py
        cost_minimization.py
    views.py
    urls.py
    asgi.py
```

### Interface Contract

```python
"""
Smart Order Router - Interface Contract

Location: services/routing/router.py
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from datetime import datetime
from decimal import Decimal
from enum import Enum
from typing import Optional, List, Dict, Any, Tuple
from uuid import UUID


class RoutingStrategy(Enum):
    """Order routing strategies."""
    BEST_PRICE = "best_price"           # Prioritize price improvement
    FASTEST = "fastest"                   # Prioritize execution speed
    LOWEST_COST = "lowest_cost"          # Minimize total cost (fees + spread)
    SMART = "smart"                       # Adaptive based on order characteristics
    INTERNALIZE_FIRST = "internalize"    # Try internal matching first
    EXTERNAL_ONLY = "external"           # Route to external venues only


class VenueType(Enum):
    """Types of execution venues."""
    INTERNAL = "internal"       # Internal matching engine
    EXCHANGE = "exchange"       # Primary exchange (NYSE, NASDAQ)
    ATS = "ats"                 # Alternative Trading System
    DARK_POOL = "dark_pool"     # Dark pool venue
    MARKET_MAKER = "market_maker"  # Market maker internalization


class ExecutionQuality(Enum):
    """Execution quality rating."""
    EXCELLENT = "excellent"    # Price improvement > 50%
    GOOD = "good"              # Price improvement > 0%
    NEUTRAL = "neutral"        # At quoted price
    POOR = "poor"              # Worse than quoted


@dataclass
class VenueQuote:
    """Quote from an execution venue."""
    venue_id: str
    venue_type: VenueType
    symbol: str
    bid_price: Decimal
    bid_size: Decimal
    ask_price: Decimal
    ask_size: Decimal
    timestamp: datetime
    latency_ms: float          # Estimated execution latency
    fee_per_share: Decimal     # Venue fee
    rebate_per_share: Decimal  # Maker rebate (if applicable)


@dataclass
class RoutingDecision:
    """Routing decision for an order."""
    order_id: UUID
    venue_id: str
    venue_type: VenueType
    expected_price: Decimal
    expected_fill_rate: float  # Probability of fill (0-1)
    expected_latency_ms: float
    estimated_cost: Decimal    # Total cost including fees
    routing_reason: str        # Human-readable explanation
    alternatives: List[Dict[str, Any]]  # Other venues considered


@dataclass
class ExecutionReport:
    """Report of order execution."""
    order_id: UUID
    venue_id: str
    executed_quantity: Decimal
    executed_price: Decimal
    execution_time: datetime
    latency_ms: float
    fee_charged: Decimal
    price_improvement: Decimal  # vs. NBBO at order time
    execution_quality: ExecutionQuality


@dataclass
class VenueStats:
    """Historical statistics for a venue."""
    venue_id: str
    symbol: str
    avg_fill_rate: float
    avg_latency_ms: float
    avg_price_improvement: Decimal
    total_volume_routed: Decimal
    success_rate: float
    last_updated: datetime


class ExecutionVenue(ABC):
    """Abstract base class for execution venues."""

    @property
    @abstractmethod
    def venue_id(self) -> str:
        """Unique venue identifier."""
        pass

    @property
    @abstractmethod
    def venue_type(self) -> VenueType:
        """Type of venue."""
        pass

    @abstractmethod
    async def get_quote(
        self,
        symbol: str,
        side: str,
        quantity: Decimal,
    ) -> VenueQuote:
        """
        Get current quote from the venue.

        Args:
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Order quantity

        Returns:
            Current quote including depth, fees
        """
        pass

    @abstractmethod
    async def submit_order(
        self,
        order_id: UUID,
        symbol: str,
        side: str,
        quantity: Decimal,
        price: Optional[Decimal] = None,
        order_type: str = "limit",
    ) -> ExecutionReport:
        """
        Submit order to the venue.

        Args:
            order_id: Order ID
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Order quantity
            price: Limit price (None for market)
            order_type: Order type

        Returns:
            Execution report
        """
        pass

    @abstractmethod
    async def cancel_order(
        self,
        order_id: UUID,
    ) -> bool:
        """
        Cancel order at the venue.

        Args:
            order_id: Order ID

        Returns:
            True if cancelled successfully
        """
        pass

    @abstractmethod
    def get_stats(
        self,
        symbol: str,
    ) -> VenueStats:
        """
        Get historical statistics for symbol at this venue.

        Args:
            symbol: Trading symbol

        Returns:
            Historical performance statistics
        """
        pass


class SmartOrderRouter:
    """
    Smart Order Router for optimal order execution.

    Analyzes multiple execution venues and routes orders to achieve
    best execution based on configurable strategies.
    """

    def __init__(
        self,
        venues: List[ExecutionVenue],
        default_strategy: RoutingStrategy = RoutingStrategy.SMART,
        redis_url: str = "redis://redis:6379/6",
    ):
        """
        Initialize the smart order router.

        Args:
            venues: List of available execution venues
            default_strategy: Default routing strategy
            redis_url: Redis URL for caching
        """
        pass

    async def route_order(
        self,
        order_id: UUID,
        user_id: UUID,
        symbol: str,
        side: str,
        quantity: Decimal,
        price: Optional[Decimal] = None,
        order_type: str = "limit",
        strategy: Optional[RoutingStrategy] = None,
        constraints: Optional[Dict[str, Any]] = None,
    ) -> RoutingDecision:
        """
        Route an order to the optimal venue.

        Args:
            order_id: Order ID
            user_id: User ID (for stats tracking)
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Order quantity
            price: Limit price (None for market)
            order_type: Order type
            strategy: Routing strategy (uses default if None)
            constraints: Optional constraints (max_fee, min_fill_rate, etc.)

        Returns:
            Routing decision with selected venue and rationale
        """
        pass

    async def route_and_execute(
        self,
        order_id: UUID,
        user_id: UUID,
        symbol: str,
        side: str,
        quantity: Decimal,
        price: Optional[Decimal] = None,
        order_type: str = "limit",
        strategy: Optional[RoutingStrategy] = None,
    ) -> ExecutionReport:
        """
        Route and execute an order in one call.

        Args:
            order_id: Order ID
            user_id: User ID
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Order quantity
            price: Limit price
            order_type: Order type
            strategy: Routing strategy

        Returns:
            Execution report from the venue
        """
        pass

    async def split_order(
        self,
        order_id: UUID,
        user_id: UUID,
        symbol: str,
        side: str,
        quantity: Decimal,
        price: Optional[Decimal] = None,
        max_venues: int = 3,
    ) -> List[Tuple[RoutingDecision, Decimal]]:
        """
        Split a large order across multiple venues.

        Args:
            order_id: Order ID
            user_id: User ID
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Total order quantity
            price: Limit price
            max_venues: Maximum venues to split across

        Returns:
            List of (routing decision, quantity) tuples
        """
        pass

    async def get_nbbo(
        self,
        symbol: str,
    ) -> Dict[str, Any]:
        """
        Get National Best Bid and Offer across all venues.

        Args:
            symbol: Trading symbol

        Returns:
            NBBO with best bid/ask prices and sizes
        """
        pass

    async def get_venue_rankings(
        self,
        symbol: str,
        side: str,
        quantity: Decimal,
    ) -> List[Dict[str, Any]]:
        """
        Get ranked list of venues for an order.

        Args:
            symbol: Trading symbol
            side: 'buy' or 'sell'
            quantity: Order quantity

        Returns:
            Venues ranked by expected execution quality
        """
        pass

    def register_venue(
        self,
        venue: ExecutionVenue,
    ) -> None:
        """
        Register a new execution venue.

        Args:
            venue: Venue to register
        """
        pass

    def unregister_venue(
        self,
        venue_id: str,
    ) -> None:
        """
        Unregister an execution venue.

        Args:
            venue_id: Venue ID to unregister
        """
        pass

    async def update_venue_stats(
        self,
        execution_report: ExecutionReport,
    ) -> None:
        """
        Update venue statistics after execution.

        Args:
            execution_report: Execution report to record
        """
        pass

    def get_routing_stats(
        self,
        user_id: Optional[UUID] = None,
        symbol: Optional[str] = None,
        start_date: Optional[datetime] = None,
        end_date: Optional[datetime] = None,
    ) -> Dict[str, Any]:
        """
        Get routing statistics for reporting.

        Args:
            user_id: Optional filter by user
            symbol: Optional filter by symbol
            start_date: Start of period
            end_date: End of period

        Returns:
            Routing statistics including venue distribution, quality metrics
        """
        pass
```

### Required Models

```python
"""
Routing service Django models.

Location: services/routing/models.py
"""
from decimal import Decimal
from uuid import uuid4
from django.db import models


class RoutingDecisionLog(models.Model):
    """Log of routing decisions for audit and analysis."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    order_id = models.UUIDField(db_index=True)
    user_id = models.UUIDField(db_index=True)
    symbol = models.CharField(max_length=20, db_index=True)
    side = models.CharField(max_length=10)
    quantity = models.DecimalField(max_digits=20, decimal_places=8)
    price = models.DecimalField(max_digits=20, decimal_places=8, null=True)
    strategy = models.CharField(max_length=50)
    selected_venue = models.CharField(max_length=50)
    expected_price = models.DecimalField(max_digits=20, decimal_places=8)
    expected_fill_rate = models.DecimalField(max_digits=5, decimal_places=4)
    routing_reason = models.TextField()
    alternatives_considered = models.JSONField()
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        app_label = "routing"
        db_table = "routing_decisions"
        indexes = [
            models.Index(fields=["user_id", "created_at"]),
            models.Index(fields=["symbol", "created_at"]),
        ]


class ExecutionLog(models.Model):
    """Log of order executions."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    order_id = models.UUIDField(db_index=True)
    routing_decision = models.ForeignKey(RoutingDecisionLog, on_delete=models.CASCADE)
    venue_id = models.CharField(max_length=50, db_index=True)
    executed_quantity = models.DecimalField(max_digits=20, decimal_places=8)
    executed_price = models.DecimalField(max_digits=20, decimal_places=8)
    latency_ms = models.DecimalField(max_digits=10, decimal_places=3)
    fee_charged = models.DecimalField(max_digits=20, decimal_places=8)
    price_improvement = models.DecimalField(max_digits=20, decimal_places=8)
    execution_quality = models.CharField(max_length=20)
    executed_at = models.DateTimeField()
    created_at = models.DateTimeField(auto_now_add=True)

    class Meta:
        app_label = "routing"
        db_table = "execution_logs"
        indexes = [
            models.Index(fields=["venue_id", "executed_at"]),
        ]


class VenueConfiguration(models.Model):
    """Configuration for execution venues."""

    venue_id = models.CharField(max_length=50, primary_key=True)
    venue_type = models.CharField(max_length=50)
    display_name = models.CharField(max_length=100)
    enabled = models.BooleanField(default=True)
    connection_config = models.JSONField()  # URLs, credentials, etc.
    fee_schedule = models.JSONField()       # Fee structure
    supported_symbols = models.JSONField(default=list)  # Empty = all
    max_order_size = models.DecimalField(max_digits=20, decimal_places=8, null=True)
    priority = models.IntegerField(default=0)  # Higher = preferred
    updated_at = models.DateTimeField(auto_now=True)

    class Meta:
        app_label = "routing"
        db_table = "venue_configurations"


class VenuePerformance(models.Model):
    """Aggregated venue performance metrics."""

    id = models.UUIDField(primary_key=True, default=uuid4, editable=False)
    venue_id = models.CharField(max_length=50, db_index=True)
    symbol = models.CharField(max_length=20, db_index=True)
    date = models.DateField(db_index=True)
    order_count = models.IntegerField(default=0)
    fill_count = models.IntegerField(default=0)
    total_quantity = models.DecimalField(max_digits=20, decimal_places=8)
    total_fees = models.DecimalField(max_digits=20, decimal_places=8)
    total_price_improvement = models.DecimalField(max_digits=20, decimal_places=8)
    avg_latency_ms = models.DecimalField(max_digits=10, decimal_places=3)

    class Meta:
        app_label = "routing"
        db_table = "venue_performance"
        unique_together = [["venue_id", "symbol", "date"]]
```

### Architectural Patterns to Follow

1. **Async Venue Communication**: Use async/await for all venue interactions
2. **Circuit Breaker**: Apply circuit breaker pattern from `shared/clients/base.py` for venue connections
3. **Event Publishing**: Publish routing decisions and executions to Kafka for audit trail
4. **Caching**: Cache venue quotes with short TTL (< 1 second) for NBBO calculation
5. **Decimal Precision**: Use `Decimal` for all price/quantity calculations
6. **Strategy Pattern**: Implement routing strategies as pluggable components

### Acceptance Criteria

#### Unit Tests (35+ tests)
- [ ] Test each routing strategy independently
- [ ] Test order splitting algorithm
- [ ] Test NBBO calculation across multiple venues
- [ ] Test venue ranking with various market conditions
- [ ] Test constraints enforcement (max fee, min fill rate)
- [ ] Test failover when primary venue is unavailable

#### Integration Tests (15+ tests)
- [ ] Test integration with internal matching engine
- [ ] Test mock external venue communication
- [ ] Test routing decision logging and audit trail
- [ ] Test venue performance statistics aggregation
- [ ] Test circuit breaker behavior with venue failures

#### Performance Tests (5+ tests)
- [ ] Routing decision latency < 5ms for 3 venues
- [ ] NBBO calculation < 2ms
- [ ] Order splitting optimization < 10ms
- [ ] Handle 1000 routing requests/second

#### Coverage Requirements
- [ ] Minimum 90% line coverage
- [ ] Minimum 85% branch coverage
- [ ] 100% coverage of routing algorithms

#### Integration Points
- [ ] Call internal Matching Engine for internalization
- [ ] Receive orders from Orders service
- [ ] Publish to `routing.decisions` and `routing.executions` Kafka topics
- [ ] Subscribe to market data for quote updates
- [ ] Expose REST API for routing statistics (SEC Rule 606 reporting)

---

## General Guidelines for All Tasks

### Code Quality
- Follow PEP 8 and type hints throughout
- Use `Decimal` for all financial calculations (avoid float precision bugs)
- Implement proper error handling with specific exception types
- Include comprehensive docstrings for all public methods

### Testing
- Use pytest with fixtures for test data
- Mock external services in unit tests
- Use test containers for integration tests requiring databases
- Measure test coverage with pytest-cov

### Documentation
- Include inline comments for complex algorithms
- Document all public APIs with OpenAPI/Swagger
- Provide example requests/responses in docstrings

### Security
- Validate all input data
- Use parameterized queries (Django ORM handles this)
- Log sensitive operations for audit
- Follow principle of least privilege for service accounts
